[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/KingaS03/Mathematics-for-Machine-Learning-and-Data-Science/master)

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/KingaS03/Mathematics-for-Machine-Learning-and-Data-Science)

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to the Mathematics Module for ML and DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to consider a common machine learning context, as this is illustrating all the major components of our course.\n",
    "\n",
    "## 1.1. Machine learning versus classical programming\n",
    "First let's take a look at machine learning and compare it with classical programming.\n",
    "\n",
    "------------------------------------\n",
    "*Machine Learning is the \"field of study that gives computers the ability to learn without being explicitly programmed.\"* - Arthur Samuel, 1959\n",
    "\n",
    "-------------------------------------\n",
    "\n",
    "<center>\n",
    "<img src=\"Images/TraditionalProgr.png\" width=\"300\"> \n",
    "</center>\n",
    "\n",
    "versus\n",
    "\n",
    "<center>\n",
    "<img src=\"Images/MachineLearning0.png\" width=\"300\"> \n",
    "</center>\n",
    "\n",
    "In case of some machine learning problems the resulting rules can be conceived as a model, which for any input data is able to predict the associated output. \n",
    "\n",
    "<center>\n",
    "<img src=\"Images/MachineLearning1.png\" width=\"300\"> \n",
    "</center>\n",
    "\n",
    "Mathematically we can think of this model as a function that assigns to an input value a predicted output value and at the same time it depends also on some model parameters (weights and intercept). The model parameters are determined in such a way to minimise the loss function. This phenomenon is concisely described in the following quote:\n",
    "\n",
    "-----------\n",
    "*\"A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.\"* - Tom Mitchell, 1997\n",
    "\n",
    "---------------\n",
    "\n",
    "## 1.2. Simple machine learning setting - Linear regression\n",
    "One of the simplest settings of a machine learning algorithm is the linear regression. To get a quick intuition about how it works play with the below interactive graph. You can change the position of the blue datapoints by dragging them with the mouse. You can change the position of the red line by moving the two red points of it.\n",
    "\n",
    "What happens on the plot on the right hand side if you change the position of one of the red points? How can you explain the observed behaviou?\n",
    "\n",
    "Take a look at the blue end red values in the upper right corner. How do these values change?\n",
    "\n",
    "What is the starting point of a regression analysis and what is its objective?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1400\"\n",
       "            height=\"600\"\n",
       "            src=\"https://www.geogebra.org/classic/gvtvpem2\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x102df97f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "#IFrame(\"https://www.geogebra.org/m/xC6zq7Zv\",800,800)\n",
    "IFrame(\"https://www.geogebra.org/classic/gvtvpem2\", 1400, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a concrete numerical example:\n",
    "\n",
    "We would like to predict the price of apartments as a linear function of their surface.\n",
    "\n",
    "We consider the following data points:\n",
    "    \n",
    "| Surface area in $m^2$ | Price in tausends of CHF | \n",
    "| --------------- | --------------- |\n",
    "| 40| 275| \n",
    "| 70 | 500 | \n",
    "| 80 | 470 | \n",
    "| 100 | 650 | \n",
    "| 115 | 690 | \n",
    "| 120 | 750 | \n",
    "\n",
    "The surface area, denoted by $x$, is the single **explanatory/dependent variable**. \n",
    "\n",
    "The price, denoted by $y$, is the single **independent variable**.\n",
    "\n",
    "The apartments, whose prices are enlisted in the above table are called **observations** and we will refer to their **features** (surface and price) as $x_i$, respectively $y_i$, where $i$ is the index of the apartment ($i = \\overline{0,5}$).\n",
    "\n",
    "We would like to approximate our data points by a line defined by the equation\n",
    "$$ y = w\\cdot x + b,$$\n",
    "where $w$ is called **weight/gradient** and $b$ is called **intercept**. These parameters $w$ and $b$ are determined in such a way that the mean squared error of the approximations is minimal.\n",
    "\n",
    "For our set of apartments the **$MSE$ (mean squared error)** can be calculated as follows:\n",
    "$$\\begin{align*}\n",
    "MSE &= \\frac{1}{6}\\sum_{i=0}^5 \\left(y_i - (w \\cdot x_i + b)\\right)^2\\\\\n",
    "& = \\left(275-(w\\cdot 40 + b)\\right)^2 + \\left(500-(w\\cdot 70 + b)\\right)^2 + \\left(470-(w\\cdot 80 + b)\\right)^2 + \\left(650-(w\\cdot 100 + b)\\right)^2 + \\left(690-(w\\cdot 115 + b)\\right)^2 + \\left(750-(w\\cdot 120 + b)\\right)^2\n",
    "\\end{align*}$$\n",
    "\n",
    "$MSE$ is a function of the parameters $b$ and $w$.\n",
    "\n",
    "The goal is to determine the parameters $b$ and $w$ in such a way to obtain the minimal $MSE$.\n",
    "\n",
    "Experiment with the following code. Fit the red line to the data points by trying out different values for the parameters $w$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Price (tausend CHF)')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 300 random samples\n",
    "x = np.array([40, 70, 80, 100, 115, 120])\n",
    "y = np.array([275, 500, 470, 650, 690, 750])\n",
    "\n",
    "plt.plot(x, y, 'o') #scatter plot of data points\n",
    "\n",
    "w = 5 # change this value\n",
    "b = 0 # change this value\n",
    "\n",
    "plt.plot(x, b + w*x) #add line of best fit\n",
    "\n",
    "MSE = np.mean((y-(b + w*x))**2)\n",
    "\n",
    "# legend, title, and labels.\n",
    "plt.text(40,700, f\"MSE ={MSE:.2f}\")\n",
    "plt.title('Surface area and price of apartments', size=18)\n",
    "plt.xlabel('Surface (m^2)', size=18)\n",
    "plt.ylabel('Price (tausend CHF)', size=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare your values with the optimal ones, by running the code<br> \n",
    "`w, b = np.polyfit(x, y, 1)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the simplicity of the linear model, it is possible to derive the explicit formulas for the parameters by calculating the partial derivatives of the $MSE$ w.r.t. the parameters and setting the values of these to $0$. Without detailed explanation \n",
    "$$\\frac{\\partial MSE}{\\partial w} = 0, \\quad \\frac{\\partial MSE}{\\partial b} = 0$$\n",
    "one can conclude:\n",
    "$$\\left\\{\\begin{align*}\n",
    "w &= \\frac{\\sum\\limits_i (x_i - \\overline{x})\\cdot (y_i-\\overline{y})}{\\sum\\limits_i(x_i - \\overline{x})^2} = 5.70\\\\\n",
    "b &= \\overline{y}-w\\cdot \\overline{x} = 57.30\n",
    "\\end{align*}\\right.\n",
    "$$\n",
    "where $\\overline{x} = \\frac{\\sum_i x_i}{n}$ and $\\overline{y} = \\frac{\\sum_i y_i}{n}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Neuronal networks\n",
    "The above univariate linear regression model can be presented as\n",
    "\n",
    "<center>\n",
    "<img src=\"Images/Network0.png\" width=\"300\"> \n",
    "</center>\n",
    "\n",
    "For the future notation we leave away the virtual input of 1.\n",
    "\n",
    "Now we make the model more complex until we get to the a two-layer neuronal network. First we apply an activation function $g$ to the linear transformation $b+w \\cdot x$.\n",
    "\n",
    "<center>\n",
    "<img src=\"Images/Network1.png\" width=\"320\"> \n",
    "</center>\n",
    "\n",
    "The above red ball corresponds to the smallest building unit of a neuronal network, namely a neuron. In a neuron:\n",
    "- there happens a linear transformation\n",
    "- to which an activation function is applied and this provides the output of the neuron.\n",
    "\n",
    "Next we allow for more inputs. \n",
    "<center>\n",
    "<img src=\"Images/MultiNetwork00.png\" width=\"320\"> \n",
    "</center>\n",
    "\n",
    "Finally we allow also for more outputs and we have two hidden layers. \n",
    "<center>\n",
    "<img src=\"Images/MultiNetwork2.png\" width=\"500\"> \n",
    "</center>\n",
    "\n",
    "The number of hidden layers indicates that the last neuronal network is a two-layer neuronal network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Motivation\n",
    "\n",
    "Exactly as in the case of linear regression the weight matrices $W^{(1)}$, $W^{(2)}$, respectively the intercepts $b^{(1)}$ and $b^{2}$ will be parameters of the loss function which is subject to minimisation. In the general case there is no immediate straightforward formula for the optimal parameters. \n",
    "<center>\n",
    "The minimum of the loss function can be approximated by the **gradient descent** method. \n",
    "    $$\\hspace{-2cm}\\Uparrow$$\n",
    "For the gradient descent method we should be able to derive the **partial derivatives** of the outputs w.r.t. all parameters of the model.\n",
    "    $$\\hspace{-2cm}\\Uparrow$$\n",
    "For neuronal networks with more hidden layers and differentiable activation functions these partial derivatives can be deremined by the **chain rule**.\n",
    "$$\\hspace{-2cm}\\Uparrow$$\n",
    "To apply the chain rule for a setting like in the last network, one needs to perform **matrix multiplications**.\n",
    "</center>\n",
    "\n",
    "The number of machine learning algorithms is large. That's why generally a huge amount of input data is needed to determine the model parameters. Alternatively, if we don't possess that much data, we can reduce the dimensionality of the input data (and by that we end up also with a smaller number of model parameters). For dimensionality reduction we can use the **PCA (principal component analysis)**, which is the same as singular value decomposition. The first name is used more in the circle of statisticians and the second name is more popular among theoretical mathematicians. To derive PCA, we need the notion of **orthogonal projection**, **eigenvalues and eigenvectors**, **the method of Lagrange multipliers** and some **descriptive statistics**.\n",
    "\n",
    "Furthermore, when the output of a neuronal network is a distribution, **probability theory** will be needed also to measure the distance between the observed distribution and the predicted one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Schedule\n",
    "1. day - linear algebra\n",
    " - vector operations\n",
    "     - vector addition, \n",
    "     - vector substraction, \n",
    "     - multiplication of a vector by a scalar\n",
    "     - the dot product\n",
    " - matrix operations\n",
    "     - matrix addition\n",
    "     - matrix substraction\n",
    "     - multiplication of a matrix by a scalar\n",
    "     - matrix multiplication\n",
    "     - inverse of a square matrix\n",
    " - projection ad the dot product\n",
    " - orthogonal matrices\n",
    " - change of basis\n",
    " - eigenvalues and eigenvectors of matrices\n",
    "2. day - calculus\n",
    "3. day - PCA\n",
    "4. day - probability theory and statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Motivation\n",
    "We are able to solve equations of the form:\n",
    "$ax + b = c$, where $a,b,c$ are real coefficients and $x$ is the unknown variable.\n",
    "\n",
    "For example we can follow the next steps to solve the  $5x + 3 = 13$ equation\n",
    "\n",
    "$$\\begin{align*}\n",
    "5x + 3 &= 13 \\quad | -3\\\\\n",
    "5x &= 10 \\quad | : 5\\\\\n",
    "x &= 2\\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "or equivalently\n",
    "\n",
    "$$\\begin{align*}\n",
    "5x + 3 &= 13 \\quad | +(-3)\\\\\n",
    "5x &= 10 \\quad | \\cdot 5^{-1}\\\\\n",
    "x &= 2\\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "Let us consider the following set-up. You have beakfast together with some of your colleagues and you are paying by turn. You don't know the price of each ordered item, but you remember what was ordered on the previous three days and how much did your colleagues pay for it each time: \n",
    "- 3 days ago your group has ordered 5 croissants, 4 coffees and 3 juices and they have payed 32.3 CHF.\n",
    "- 2 days ago your group has ordered 4 croissant, 5 coffees and 3 juices and they payed 32.5 CHF.\n",
    "- 1 day ago the group has ordered 6 croissants, 5 coffees and 2 juices and that costed 31 CHF.\n",
    "\n",
    "Today the group has ordered 7 croissants, 4 coffees and 2 juices and you would like to know whether the amount of 35 CHF available on your uni card will cover the consumption or you need to recharge it before paying.\n",
    "\n",
    "By introducing the notations\n",
    "- $x_1$ for the price of a croissant,\n",
    "- $x_2$ for the price of a coffee,\n",
    "- $x_3$ for the price of a juice,\n",
    "then our information about the consumption of the previous 3 days can be summarised in the form of the following 3 linear equations <br><br>\n",
    "$$\\left\\{\\begin{align}\n",
    "&5\\cdot x_1 + 4 \\cdot x_2 + 3 \\cdot x_3 = 32.3 \\\\\n",
    "&4\\cdot x_1 + 5 \\cdot x_2 + 3 \\cdot x_3 = 32.5 \\\\\n",
    "&6\\cdot x_1 + 5 \\cdot x_2 + 2 \\cdot x_3 = 31\n",
    "\\end{align}\\right.$$\n",
    "<br>\n",
    "The quantity ordered on the current day is $7\\cdot x_1 + 4 \\cdot x_2 + 2 \\cdot x_3$. To determine this one possibility is to calculate the price of each product separately, i.e. we solve the linear equation system first and then susbstitute the prices in the previous formula.\n",
    "\n",
    "The above system in matrix form\n",
    "<br><br>\n",
    "$$\n",
    "\\left(\\begin{array}{ccc}\n",
    "5 & 4 & 3\\\\\n",
    "4 & 5 & 3\\\\\n",
    "6 & 5 & 2\n",
    "\\end{array}\n",
    "\\right)\\cdot \\left(\\begin{array}{c}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "x_3 \n",
    "\\end{array}\n",
    "\\right) = \n",
    "\\left(\\begin{array}{c}\n",
    "32.3\\\\\n",
    "32.5\\\\\n",
    "31 \n",
    "\\end{array}\n",
    "\\right)$$\n",
    "<br>\n",
    "If we introduce for the matrix, respectively the two vectors in the above formula the notations $A, x, b$, then we get <br><br>\n",
    "$$A \\cdot x = b$$\n",
    "<br>\n",
    "One can observe that formally this looks the same as the middle state of our introductory linear equation with real coefficients $5x = 10$. So our goal is to perform a similar operation as there, namely we are looking for teh operation that would make $A$ dissappear from the left hand side of the equation. We will see later that this operation will be the inverse operation of multiplication by a matrix, namely multiplication by the inverse of a matrix.\n",
    "\n",
    "In our applications we will encounter for example when deriving the weights of the multivariate linear regression, a matrix equation of the form:\n",
    "$A \\cdot x + b = 0$. This example motivates the introduction of vector substraction, as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Vectors\n",
    "\n",
    "Vectors are elements of a linear vector space.\n",
    "The vector space we are going to work with is $\\mathbb{R}^n$, where $n$ is the dimension of the space and it can be $1, 2, 3, 4, ...$. An element of such a vector space can be described by an ordered list of $n$ components of the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Geometrical representation of vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below a 2-dimensional vector is represented. You can move its endpoints on the grid and you will see how do its components change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://www.geogebra.org/classic/cnvxpycc\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1124449b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://www.geogebra.org/classic/cnvxpycc\", 800, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the 3-dimensional vector in the interactive window below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://www.geogebra.org/classic/meg4scuj\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1124bd438>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://www.geogebra.org/classic/meg4scuj\", 800, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following interactive window explains when are two vectors equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://www.geogebra.org/classic/fkkbkvuj\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1124bd278>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://www.geogebra.org/classic/fkkbkvuj\", 800, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Vector addition and substraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://www.geogebra.org/classic/jnchvrhg\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1124bdb70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://www.geogebra.org/classic/jnchvrhg\", 800, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see another approach to vector addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"600\"\n",
       "            src=\"https://www.geogebra.org/classic/mzgchv22\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1124bdc50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://www.geogebra.org/classic/mzgchv22\", 1200, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Multiplication of vectors by a scalar\n",
    "This happens also component-wise exactly as addition, namely\n",
    "$$\\lambda  (x_1, x_2, \\ldots, x_n) = (\\lambda x_1, \\lambda x_2, \\ldots, \\lambda x_n).$$\n",
    "This operation is illustrated below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"800\"\n",
       "            src=\"https://www.geogebra.org/classic/gxhsev8k\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1124cb320>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://www.geogebra.org/classic/gxhsev8k\", 800, 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4. Abstract linear algebra terminology\n",
    "\n",
    "1. For any two elements $x,y \\in \\mathbb{R}^n$ it holds that\n",
    "$$x+y \\in \\mathbb{R}^n.$$\n",
    "This property is called **closedness** of $\\mathbb{R}^n$ w.r.t. addition.\n",
    "\n",
    "2. Observe the **commutativity** of the addition on $\\mathbb{R}^n$ is inherited by the vectors in $\\mathbb{R}^n$, i.e. $$x + y = y + x$$ for any $x, y \\in \\mathbb{R}^n$.\n",
    "\n",
    "3. Observe that addition is also **associative** on $\\mathbb{R}^n$, i.e.\n",
    "$$x + (y + z) = (x + y) + z, \\quad \\mbox{ for any } x,y,z \\in \\mathbb{R}^n$$\n",
    "\n",
    "4. If we add the null vector $\\mathbf{0} = (0, 0, ..., 0) \\in \\mathbb{R}^n$ to any other vector $x \\in \\mathbb{R}^n$ it holds that\n",
    "$$\\mathbf{0} + x = x + \\mathbf{0} = x.$$\n",
    "The single element with the above property is called the **neutral element** w.r.t. addition.\n",
    "\n",
    "5. For a vector $x = (x_1, x_2, \\ldots, x_n)$ the vector $x^*$ for which\n",
    "$$x + x^* = x^* + x = \\mathbf{0}$$\n",
    "is called the **inverse vector** of $x$ w.r.t. addition.\n",
    "\n",
    "What is the inverse of the vector $x = (2, 3, -1)$?\n",
    "\n",
    "What is the inverse of a vector $x = (x_1, x_2, \\ldots, x_n)$?\n",
    "\n",
    "As every vector of $\\mathbb{R}^n$ possesses an inverse, we introduce the notation $-x$ for its inverse  w.r.t addition.\n",
    "\n",
    "A set $V$ with an operation $\\circ$ that satsifies the above properties is called a **commutative or Abelian group** in linear algebra. For us $V = \\mathbb{R}^n$ and $\\circ = +$.\n",
    "\n",
    "The scalar mutiplication, that we have introduced, has the following properties\n",
    "6. **associativity** of multiplication: $(\\lambda_1\\lambda_2) x = \\lambda_1 (\\lambda_2x)$, \n",
    "7. **distributivity**: $(\\lambda_1 + \\lambda_2) x = \\lambda_1  x + \\lambda_2  x$ and $\\lambda(x+y) = \\lambda x + \\lambda y$,\n",
    "8. **unitarity**: $1 x = x$,\n",
    "for all $x,y \\in \\mathbb{R}^n$ and $\\lambda, \\lambda_1, \\lambda_2$ scalars.\n",
    "\n",
    "Our scalars are elements of $\\mathbb{R}$. This set is a **field**, i.e. the operations $\\lambda_1+\\lambda_2$, $\\lambda_1-\\lambda_2$, $\\lambda_1\\cdot\\lambda_2$ make sense for any $\\lambda_1, \\lambda_2 \\in \\mathbb{R}$ and the $\\lambda_1/\\lambda_2 = \\lambda_1 \\cdot \\lambda_2^{-1}$ can be performed also when $\\lambda_2 \\neq 0$.\n",
    "\n",
    "A **vector space** consists of a set $V$ and a field $F$ and two operations:\n",
    "- an operation called vector  addition that takes two vectors $v,w \\in V$, and produces a third vector, written $v+w \\in V$,\n",
    "- an operation called scalar multiplication that takes a scalar $\\lambda \\in F$ and a vector $v\\in V$, and produces a new vector, written $cv \\in V$,\n",
    "which satisfy all the properties enlisted above (5+3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.5. Modulus of a vector, length of a vector, size of a vector\n",
    "\n",
    "The length of a vector or norm of a vector $x = (x_1, x_2, \\cdots, x_n)$ is given by the formula\n",
    "$$||x|| = ..........$$\n",
    "\n",
    "Experiment with the interactive window below and derive the missing formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://www.geogebra.org/classic/mfzdes3n\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1124cb358>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://www.geogebra.org/classic/mfzdes3n\", 800, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.6. Dot product or inner product\n",
    "The **dot product of inner product** of two vectors $x = (x_1, x_2)$ and $y = (y_1, y_2)$ is denoted by $x \\cdot y$ and it is equal to the scalar $x_1\\cdot y_1+ x_2 \\cdot y_2$.\n",
    "\n",
    "This can be generalised to the vectors $x = (x_1, x_2, \\cdots, x_n) \\in \\mathbb{R}^n$ and $y = (y_1, y_2, \\cdots, y_n) \\in \\mathbb{R}^n$ as ............ .\n",
    "\n",
    "Observe that as a consequence of the definition distributivity over addition holds, i.e. $x \\cdot(y + z) = x \\cdot y + x \\cdot z$.\n",
    "\n",
    "Furthermore $\\lambda x \\cdot y = \\lambda x\\cdot y = x \\cdot \\lambda y$.\n",
    "\n",
    "The last two properties together are called also **bilinearity** of the scalar product.\n",
    "\n",
    "Observe also that the scalar product is **commutative**, i.e. $x \\cdot y = y \\cdot x$.\n",
    "\n",
    "What's the relation between the length of a vector and the dot product?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.7. The dot product and the cosine rule\n",
    "Derive $x \\cdot y = ||x||\\ ||y||\\ \\cos(x,y)$ writing the cosine rule in the triangle with two sides given by the vectors $x, y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.8. Scalar and vector projection\n",
    "Ex. 1. Change the canonical basis to another orthogonal basis by scalar projection.\n",
    "\n",
    "Ex. 2. In PCA we can project basically on the first eigenvector and on its orthogonal complement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.9. Basis of a vectorspace, linear independence of vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Matrices\n",
    "\n",
    "Matrices.\n",
    "\n",
    "## 2.3.1. Matrix multiplication of a vector \n",
    "Matrix multiplication of a vector  as a linear transformation that trnasforms basis vectors of the original space to basis vectors of the image space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. Gauss elimination to solve a system of linear equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3. Inverse of a matrix by Gaussian elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4. The determinant of a $2\\times 2$ matrix\n",
    "as the volume of the paralellogram spanned by the colmn vectors of the original matrix.\n",
    "\n",
    "What means if the determinant is 0?\n",
    "\n",
    "Ex. for a 3x3 system with a multiple solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5. Rotation in a different coordinate system than the canonical one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6. Orthogonal matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.7. Gram-Schmidt orthogonalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.8 Reflection in $\\mathbb{R}^3$ w.r.t. a plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.9. Eigenvectors, eigenvalues\n",
    "\"eigen\" = \"characteristic\"\n",
    "Eigenvectors are the vectors, which are just scaled by a factor when appliying the matrix operation on them.\n",
    "Eigenvalues are the solutions of characteristic polynomial.\n",
    "\n",
    "Rotation in $\\mathbb{R}^2$: no eigenvector\n",
    "\n",
    "Rotation in $\\mathbb{R}^3$: the only eigenvector is the axis of rotation\n",
    "\n",
    "Scaling along one axis: 2 eigenvectors\n",
    "\n",
    "Identity matrix: Every vector is an eigenvector\n",
    "\n",
    "## 2.3.10. Diagonalisation by changing the basis to the eigenvectors\n",
    "Application to calculating the $n$th power of a matrix. We can be interested in this question when $T$ is s transition matrix encorporating the change that happens in one time unit. Then $T^n$ shows the change happening in $n$ time units. If we can find a basis, where the matrix is diagonal, then calculate its $n$th power and afterwards transform it back, it is easier than calculating the $n$th power of the original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Question: What day of the week is it today?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20ecd1d42be4d1391a02c4694fddaff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(width='auto')), RadioButtons(options=(('a. Monday', 0), ('b. Tuesday', 1),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = create_multipleChoice_widget(\"1. Question: What day of the week is it today?\", ['a. Monday', 'b. Tuesday', 'c. Wednesday'],'b. Tuesday','[Hint]:')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.8. Eigenvectors, eigenvalues\n",
    "\"eigen\" = \"characteristic\"\n",
    "Eigenvectors are the vectors, which are just scaled by a factor when appliying the matrix operation on them.\n",
    "Eigenvalues are the solutions of characteristic polynomial.\n",
    "\n",
    "Please associate the following transformations in $\\mathbb{R}^2$ to the number of eigenvectors that they have:\n",
    "1. Rotation in $\\mathbb{R}^2$\n",
    "2. Rotation in $\\mathbb{R}^3$\n",
    "3. Scaling along one axis\n",
    "4. Scaling along 2 axis\n",
    "5. Multiplication by the identity matrix\n",
    "\n",
    "Number of eigenvectors:<br>\n",
    "a. every vector is an eigenvector<br>\n",
    "b. the transformation has exactly 2 eigenvectors<br>\n",
    "c. the transformation has exactly one eigenvectors<br>\n",
    "d. the transformation can have none or two eigenvectors\n",
    "\n",
    "\n",
    "\n",
    "### 2.3.9. Diagonalisation by changing the basis to the eigenvectors\n",
    "Application to calculating the $n$th power of a matrix. We can be interested in this question when $T$ is s transition matrix encorporating the change that happens in one time unit. Then $T$^n shows the change happening in $n$ time units. If we can find a basis, where the matrix is diagonal, then calculate its $n$th power and afterwards transform it back, it is easier than calculating the $n$th power of the original matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Homework\n",
    "Read through the material of the first day and summarise the relevant formulas, notions on a cheat sheet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
